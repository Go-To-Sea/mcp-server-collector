import requests
import os
import time
import datetime
import uuid
import re
import random
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")  # GitHub è®¿é—®ä»¤ç‰Œ
USE_PROXY = False  # æ˜¯å¦ä½¿ç”¨ä»£ç†
REQUEST_TIMEOUT = int(os.getenv("REQUEST_TIMEOUT", "10"))  # è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
MAX_RETRIES = int(os.getenv("MAX_RETRIES", "3"))  # æœ€å¤§é‡è¯•æ¬¡æ•°

# è·å–å½“å‰å¹´æœˆ
current_year = datetime.datetime.now().year
current_month = datetime.datetime.now().month

# è®¾ç½®æŸ¥è¯¢çš„å¹´ä»½èŒƒå›´ï¼ˆæœ€è¿‘ 10 å¹´ï¼‰
START_YEAR = current_year - 10  # 10 å¹´å‰
END_YEAR = current_year         # å½“å‰å¹´


def request_with_retry(url, headers, proxies=None, max_retries=MAX_RETRIES, timeout=REQUEST_TIMEOUT):
    """å¸¦é‡è¯•æœºåˆ¶çš„è¯·æ±‚å‡½æ•°"""
    for attempt in range(max_retries):
        try:
            # æ·»åŠ è½»å¾®éšæœºå»¶è¿Ÿé¿å…è¯·æ±‚è¿‡äºé›†ä¸­
            if attempt > 0:
                delay = random.uniform(1, 3) * attempt
                print(f"â³ ç­‰å¾… {delay:.2f} ç§’åè¿›è¡Œç¬¬ {attempt+1} æ¬¡é‡è¯•...")
                time.sleep(delay)
                
            kwargs = {
                "headers": headers,
                "timeout": timeout
            }
            if proxies:
                kwargs["proxies"] = proxies
                
            response = requests.get(url, **kwargs)
            return response
        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:
            print(f"âš ï¸ è¿æ¥è¶…æ—¶æˆ–é”™è¯¯ (å°è¯• {attempt+1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                print(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒè¯·æ±‚: {url}")
                raise
        except Exception as e:
            print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
            raise
    
    return None


def get_readme_content(repo_full_name):
    """è·å–ä»“åº“çš„READMEå†…å®¹"""
    headers = {"Accept": "application/vnd.github.v3+json"}
    if GITHUB_TOKEN:
        headers["Authorization"] = f"Bearer {GITHUB_TOKEN}"
    
    # è®¾ç½®ä»£ç†
    proxies = None
    if not USE_PROXY:
        proxies = {"http": None, "https": None}  # ç¦ç”¨ä»£ç†
    
    # å°è¯•è·å–ä¸åŒæ ¼å¼çš„READMEæ–‡ä»¶
    readme_formats = ['README.md', 'README', 'readme.md', 'Readme.md']
    for readme_format in readme_formats:
        url = f"https://api.github.com/repos/{repo_full_name}/contents/{readme_format}"
        try:
            response = request_with_retry(url, headers, proxies)
            
            if response and response.status_code == 200:
                data = response.json()
                if 'content' in data and data.get('encoding') == 'base64':
                    import base64
                    content = base64.b64decode(data['content']).decode('utf-8', errors='replace')
                    return content
        except Exception as e:
            print(f"âŒ è·å– {repo_full_name} çš„ {readme_format} æ—¶å‡ºé”™: {e}")
            continue
    
    return ""  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°READMEï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²


def extract_tags_from_text(type, text):
    """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯ä½œä¸ºæ ‡ç­¾"""
    if not text:
        return []
    
    # å¸¸è§çš„ Minecraft æœåŠ¡å™¨ç›¸å…³å…³é”®è¯
    keywords = [
        "minecraft", type, "plugin", "mod", "mcp", "forge", "spigot",
        "bukkit", "paper", "velocity", "proxy", "bungee", "waterfall", 
        "fabric", "multiplayer", "smp", "gamemode", "survival", "creative",
        "pvp", "pve", "economy", "permissions", "anti-cheat", "modpack"
    ]
    
    tags = []
    text_lower = text.lower()
    
    for keyword in keywords:
        if keyword in text_lower:
            tags.append(keyword)
    
    return tags


def get_mcp(type):
    all_results = []
    headers = {"Accept": "application/vnd.github.v3+json"}

    if GITHUB_TOKEN:
        headers["Authorization"] = f"Bearer {GITHUB_TOKEN}"
    
    # è®¾ç½®ä»£ç†
    proxies = None
    if not USE_PROXY:
        proxies = {"http": None, "https": None}  # ç¦ç”¨ä»£ç†

    # å€’åºéå†æ¯å¹´æ¯æœˆï¼ˆä»æœ€è¿‘çš„æ—¶é—´å¼€å§‹ï¼‰
    for year in range(END_YEAR, START_YEAR - 1, -1):
        # ç¡®å®šæœˆä»½èŒƒå›´
        month_start = 1
        month_end = 12
        
        # å¦‚æœæ˜¯å½“å‰å¹´ä»½ï¼Œåˆ™åªæŸ¥è¯¢åˆ°å½“å‰æœˆä»½
        if year == END_YEAR:
            month_end = current_month
            
        # å€’åºéå†æœˆä»½
        for month in range(month_end, month_start - 1, -1):
            # è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆæŒ‰æœˆï¼‰
            start_date = f"{year}-{month:02d}-01"
            if month == 12:
                end_date = f"{year + 1}-01-01"
            else:
                end_date = f"{year}-{month + 1:02d}-01"

            print(f"ğŸ” æŸ¥è¯¢ {start_date} è‡³ {end_date} çš„æ•°æ®...")

            page = 1
            while True:
                # æ„é€  GitHub API æŸ¥è¯¢ URL
                url = f"https://api.github.com/search/repositories?q=MCP+{type}+created:{start_date}..{end_date}&per_page=100&page={page}"
                try:
                    response = request_with_retry(url, headers, proxies)
                    
                    # å¦‚æœè¯·æ±‚å¤±è´¥åˆ™è·³è¿‡
                    if not response:
                        print(f"âš ï¸ æ— æ³•è·å–ä»“åº“åˆ—è¡¨ï¼Œè·³è¿‡æ—¶é—´æ®µ: {start_date} è‡³ {end_date}")
                        break
                        
                except Exception as e:
                    print(f"âŒ è¯·æ±‚ä»“åº“åˆ—è¡¨å¤±è´¥: {e}")
                    # ç­‰å¾…ä¸€æ®µæ—¶é—´åå†å°è¯•å…¶ä»–æœˆä»½
                    time.sleep(5)
                    break

                # å¤„ç†é€Ÿç‡é™åˆ¶
                if response.status_code == 403:
                    retry_after = int(response.headers.get("X-RateLimit-Reset", time.time() + 60)) - int(time.time())
                    print(f"âš ï¸ é€Ÿç‡é™åˆ¶ï¼ç­‰å¾… {retry_after} ç§’åç»§ç»­...")
                    time.sleep(retry_after)
                    continue

                elif response.status_code == 401:
                    print("âŒ GitHub è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ Token æ˜¯å¦æ­£ç¡®ã€‚")
                    return all_results

                elif response.status_code != 200:
                    print(f"âŒ è¯·æ±‚ GitHub æ•°æ®å¤±è´¥ï¼Œé”™è¯¯ä»£ç ï¼š{response.status_code}")
                    break

                data = response.json()
                repositories = data.get("items", [])

                if not repositories:
                    print(f"âœ… {start_date} ~ {end_date} çš„æ•°æ®è·å–å®Œæ¯•ï¼")
                    break  # ç»“æŸå½“å‰æœˆä»½æŸ¥è¯¢

                # å­˜å‚¨æ•°æ®
                for repo in repositories:
                    try:
                        # è·å–READMEå†…å®¹
                        readme_content = get_readme_content(repo["full_name"])
                        
                        # åˆå§‹åŒ–ä»“åº“æ•°æ®
                        repo_data = {
                            "uuid": str(uuid.uuid4()),  # ç”Ÿæˆå”¯ä¸€UUID
                            "name": repo["name"],
                            "title": repo["name"].replace("-", " ").title(),
                            "url": repo["html_url"],
                            "author_name": repo["owner"]["login"],
                            "author_avatar_url": repo["owner"]["avatar_url"],
                            "avatar_url": repo["owner"]["avatar_url"],  # ä½¿ç”¨ä½œè€…å¤´åƒä½œä¸ºé¡¹ç›®å¤´åƒ
                            "type": type,
                            "created_at": repo["created_at"],
                            "updated_at": repo["updated_at"],
                            "status": "created",  # é»˜è®¤çŠ¶æ€
                            "category": "",  # é»˜è®¤ç±»åˆ«
                            "is_featured": True,  # é»˜è®¤éç‰¹è‰²
                            "sort": 0,  # é»˜è®¤æ’åº
                            "target": "_self",  # é»˜è®¤ç›®æ ‡
                            "content": readme_content,  # READMEå†…å®¹
                            "img_url": ""  # é»˜è®¤æ— å›¾ç‰‡URL
                        }
                        
                        # ä»…å½“æœ‰æè¿°æ—¶æ·»åŠ æè¿°å­—æ®µ
                        if repo["description"]:
                            repo_data["description"] = repo["description"]
                        
                        # ç”Ÿæˆç®€çŸ­æ‘˜è¦ - åªæœ‰åœ¨æœ‰å†…å®¹æ—¶æ‰è®¾ç½®
                        if repo["description"]:
                            repo_data["summary"] = repo["description"]
                        
                        # åŠ¨æ€è·å–æ ‡ç­¾
                        tags = []
                        
                        # 1. ä»ä»“åº“ä¸»é¢˜è·å–æ ‡ç­¾
                        if "topics" in repo and repo["topics"]:
                            tags.extend(repo["topics"])
                        
                        # 2. ä»æè¿°å’ŒREADMEä¸­æå–å…³é”®è¯ä½œä¸ºæ ‡ç­¾
                        tags.extend(extract_tags_from_text(type, repo["description"]))
                        tags.extend(extract_tags_from_text(type, readme_content))
                        
                        # ç¡®ä¿è‡³å°‘æœ‰åŸºæœ¬æ ‡ç­¾
                        if not tags:
                            tags = ["MCP", type]
                        
                        # ç§»é™¤é‡å¤é¡¹ï¼Œä¿ç•™å”¯ä¸€æ ‡ç­¾
                        tags = list(set(tags))
                        
                        # å°†æ ‡ç­¾åˆ—è¡¨è½¬æ¢ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
                        repo_data["tags"] = ",".join(tags)
                        
                        # å°è¯•ä»READMEä¸­æå–å›¾ç‰‡URL
                        img_matches = re.findall(r'!\[.*?\]\((https?://\S+)\)', readme_content)
                        if img_matches:
                            repo_data["img_url"] = img_matches[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„å›¾ç‰‡URL
                        
                        if repo_data not in all_results:
                            if repo_data['content'] != '':
                                print("111")
                            all_results.append(repo_data)
                            
                    except Exception as e:
                        print(f"âŒ å¤„ç†ä»“åº“ {repo['full_name']} æ—¶å‡ºé”™: {e}")
                        continue
                
                # ç­‰å¾…ä¸€å°æ®µæ—¶é—´é¿å…è§¦å‘GitHubçš„é€Ÿç‡é™åˆ¶
                time.sleep(random.uniform(0.5, 1.5))

                if len(repositories) < 100:  # å¦‚æœå½“å‰é¡µæ•°æ®å°‘äº 100 æ¡ï¼Œè¯´æ˜å·²ç»å–å®Œäº†
                    break

                page += 1
                if page > 10:  # GitHub API é™åˆ¶æ¯ä¸ªæŸ¥è¯¢æœ€å¤š 1000 æ¡ï¼ˆ10 é¡µï¼‰
                    print(f"âš ï¸ {start_date} ~ {end_date} è¾¾åˆ° 1000 æ¡é™åˆ¶ï¼Œåœæ­¢æŸ¥è¯¢")
                    break

    return all_results


# è¿è¡Œ
if __name__ == "__main__":
    mcp_servers = get_mcp_servers('client')
    print(f"âœ… å…±è·å– {len(mcp_servers)} æ¡æ•°æ®")
